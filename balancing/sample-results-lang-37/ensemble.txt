0: Pipeline(
	0: RobustScaler(with_centering=False)
	1: ExtraTreesClassifier(bootstrap=True, class_weight='balanced_subsample',
                     criterion='entropy', max_features='log2',
                     min_samples_leaf=8, min_samples_split=6, n_estimators=66,
                     random_state=37)
) -> Fitness: 0.8689328608725984

1: Pipeline(
	0: RobustScaler(with_scaling=False)
	1: MaxAbsScaler()
	2: MinMaxScaler()
	3: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', min_samples_leaf=5,
                     min_samples_split=6, n_estimators=71, random_state=37)
) -> Fitness: 0.8692770065915709

2: Pipeline(
	0: RobustScaler(with_scaling=False)
	1: MaxAbsScaler()
	2: MinMaxScaler()
	3: ExtraTreesClassifier(class_weight='balanced_subsample', criterion='entropy',
                     min_samples_leaf=5, min_samples_split=6, n_estimators=71,
                     random_state=37)
) -> Fitness: 0.8716141206251313

3: Pipeline(
	0: ExtraTreesClassifier(class_weight='balanced_subsample', criterion='entropy',
                     min_samples_leaf=15, min_samples_split=11, n_estimators=22,
                     random_state=37)
) -> Fitness: 0.8609864871947023

4: Pipeline(
	0: MinMaxScaler()
	1: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       max_features=0.6184894994946681, min_samples_leaf=20,
                       min_samples_split=3, n_estimators=90, random_state=37)
) -> Fitness: 0.8560379343592899

5: Pipeline(
	0: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       max_features=0.6184894994946681, min_samples_leaf=20,
                       min_samples_split=3, n_estimators=85, random_state=37)
) -> Fitness: 0.856229505240516

6: Pipeline(
	0: RobustScaler(with_centering=False)
	1: ExtraTreesClassifier(class_weight='balanced', criterion='entropy',
                     max_features='log2', min_samples_leaf=14,
                     min_samples_split=6, n_estimators=66, random_state=37)
) -> Fitness: 0.8507636631260288

7: Pipeline(
	0: RobustScaler(with_centering=False, with_scaling=False)
	1: MaxAbsScaler()
	2: MinMaxScaler()
	3: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', min_samples_leaf=5,
                     min_samples_split=6, n_estimators=71, random_state=37)
) -> Fitness: 0.8692770065915709

8: Pipeline(
	0: MaxAbsScaler()
	1: Nystroem(coef0=0.5885898453214151, degree=5, gamma=0.31546772924811123,
         n_components=30, random_state=37)
	2: SelectFwe(alpha=0.027212126476579633)
	3: ExtraTreesClassifier(bootstrap=True, class_weight='balanced_subsample',
                     criterion='entropy', max_features='log2',
                     min_samples_leaf=8, min_samples_split=6, n_estimators=66,
                     random_state=37)
) -> Fitness: 0.8516817889040478

9: Pipeline(
	0: FastICA(algorithm='deflation', fun='exp', n_components=22, random_state=37,
        whiten='arbitrary-variance')
	1: MaxAbsScaler()
	2: VarianceThreshold()
	3: Nystroem(coef0=0.05924865299462323, degree=4, gamma=5.470181233450036,
         n_components=24, random_state=37)
	4: ExtraTreesClassifier(class_weight='balanced', criterion='entropy',
                     max_features='log2', min_samples_leaf=14,
                     min_samples_split=6, n_estimators=96, random_state=37)
) -> Fitness: 0.8435387162525029

10: Pipeline(
	0: FastICA(algorithm='deflation', fun='exp', n_components=22, random_state=37,
        whiten='arbitrary-variance')
	1: MaxAbsScaler()
	2: VarianceThreshold()
	3: Nystroem(coef0=0.05924865299462323, degree=4, gamma=5.470181233450036,
         n_components=24, random_state=37)
	4: ExtraTreesClassifier(bootstrap=True, class_weight='balanced_subsample',
                     criterion='entropy', max_features='log2',
                     min_samples_leaf=8, min_samples_split=6, n_estimators=96,
                     random_state=37)
) -> Fitness: 0.8400505567924965

11: Pipeline(
	0: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       max_features=0.6184894994946681, min_samples_leaf=20,
                       min_samples_split=3, n_estimators=16, random_state=37)
) -> Fitness: 0.8466247853667911

12: Pipeline(
	0: RobustScaler(with_scaling=False)
	1: MaxAbsScaler()
	2: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       max_features=0.6184894994946681, min_samples_leaf=20,
                       min_samples_split=3, n_estimators=16, random_state=37)
) -> Fitness: 0.8466247853667911

13: Pipeline(
	0: LogisticRegression(C=3.1200926487911658, class_weight='balanced', max_iter=1000,
                   penalty=None, random_state=37)
) -> Fitness: 0.8232664229977477

14: Pipeline(
	0: RobustScaler(with_centering=False)
	1: MaxAbsScaler()
	2: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       max_features=0.6184894994946681, min_samples_leaf=20,
                       min_samples_split=3, n_estimators=85, random_state=37)
) -> Fitness: 0.8560379343592899

15: Pipeline(
	0: SelectPercentile(percentile=70.20412941383981)
	1: LogisticRegression(C=3.1200926487911658, class_weight='balanced', max_iter=1000,
                   penalty=None, random_state=37)
) -> Fitness: 0.8241405796096902

16: Pipeline(
	0: MaxAbsScaler()
	1: PCA(n_components=0.5226448780927309, random_state=37, whiten=True)
	2: DecisionTreeClassifier(class_weight='balanced', max_depth=6,
                       max_features=0.15546649167092097, min_samples_leaf=13,
                       min_samples_split=13, random_state=37)
) -> Fitness: 0.825973379565059

17: Pipeline(
	0: VarianceThreshold()
	1: SelectPercentile(percentile=94.52857285075078)
	2: RobustScaler(with_centering=False, with_scaling=False)
	3: ExtraTreesClassifier(class_weight='balanced', min_samples_leaf=15,
                     min_samples_split=13, n_estimators=39, random_state=37)
) -> Fitness: 0.8457901460604698

18: Pipeline(
	0: RobustScaler(with_centering=False, with_scaling=False)
	1: MaxAbsScaler()
	2: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       max_features=0.6184894994946681, min_samples_leaf=20,
                       min_samples_split=3, n_estimators=16, random_state=37)
) -> Fitness: 0.8466247853667911

19: Pipeline(
	0: MaxAbsScaler()
	1: MinMaxScaler()
	2: DecisionTreeClassifier(class_weight='balanced', max_depth=4,
                       max_features=0.5085079789288117, min_samples_leaf=10,
                       min_samples_split=12, random_state=37)
) -> Fitness: 0.8215585005457756

Ensemble fitness: 0.8800716129653955
Weights: [0.9969237995472011, 0.9973186367932128, 1.0, 0.9878069512884822, 0.9821294929748614, 0.9823492816137704, 0.976078339019854, 0.9973186367932128, 0.9771317016906658, 0.9677891813495489, 0.9637872275290847, 0.9713298182452372, 0.9713298182452372, 0.9445308462961705, 0.9821294929748614, 0.9455337632880563, 0.9476365286196393, 0.9703722393274901, 0.9713298182452372, 0.9425713525115273]
Prediction: [0 0 0 ... 0 0 0]
