0: Pipeline(
	0: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    criterion='entropy',
                                                    max_depth=5,
                                                    max_features=0.3289865564527549,
                                                    min_samples_split=7,
                                                    random_state=38),
                   learning_rate=0.1489485650648153, n_estimators=81,
                   random_state=38)
) -> Fitness: 0.8422833732032959

1: Pipeline(
	0: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       criterion='entropy', min_samples_leaf=10,
                       min_samples_split=19, n_estimators=58, random_state=38)
) -> Fitness: 0.8349626346889121

2: Pipeline(
	0: MaxAbsScaler()
	1: VarianceThreshold()
	2: RandomForestClassifier(class_weight='balanced', criterion='entropy',
                       max_features=None, min_samples_leaf=7,
                       min_samples_split=10, n_estimators=93, random_state=38)
) -> Fitness: 0.8314990594778058

3: Pipeline(
	0: MaxAbsScaler()
	1: MinMaxScaler()
	2: VarianceThreshold()
	3: FastICA(algorithm='deflation', n_components=42, random_state=38,
        whiten='arbitrary-variance')
	4: RandomForestClassifier(class_weight='balanced', criterion='entropy',
                       min_samples_leaf=7, min_samples_split=10,
                       n_estimators=93, random_state=38)
) -> Fitness: 0.8314883252571101

4: Pipeline(
	0: MaxAbsScaler()
	1: VarianceThreshold()
	2: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', min_samples_leaf=3,
                     min_samples_split=6, n_estimators=99, random_state=38)
) -> Fitness: 0.8292985442352123

5: Pipeline(
	0: MinMaxScaler()
	1: MaxAbsScaler()
	2: VarianceThreshold()
	3: FastICA(algorithm='deflation', fun='exp', n_components=74, random_state=38,
        whiten='arbitrary-variance')
	4: ExtraTreesClassifier(class_weight='balanced', criterion='entropy',
                     min_samples_leaf=5, min_samples_split=4, n_estimators=68,
                     random_state=38)
) -> Fitness: 0.8356818274755158

6: Pipeline(
	0: RandomForestClassifier(bootstrap=False, class_weight='balanced',
                       criterion='entropy', min_samples_leaf=7,
                       min_samples_split=19, n_estimators=64, random_state=38)
) -> Fitness: 0.8371631499315055

7: Pipeline(
	0: MaxAbsScaler()
	1: RobustScaler(with_centering=False, with_scaling=False)
	2: VarianceThreshold()
	3: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', min_samples_leaf=3,
                     min_samples_split=6, n_estimators=99, random_state=38)
) -> Fitness: 0.8292985442352123

8: Pipeline(
	0: MaxAbsScaler()
	1: RobustScaler(with_centering=False, with_scaling=False)
	2: SelectPercentile(percentile=80.87182579566738)
	3: ExtraTreesClassifier(bootstrap=True, class_weight='balanced_subsample',
                     criterion='entropy', min_samples_leaf=3,
                     min_samples_split=6, n_estimators=99, random_state=38)
) -> Fitness: 0.8204696477130998

9: Pipeline(
	0: MaxAbsScaler()
	1: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    max_depth=4,
                                                    max_features=0.4944341708722002,
                                                    min_samples_leaf=8,
                                                    min_samples_split=4,
                                                    random_state=38),
                   learning_rate=0.09285916727857113, n_estimators=52,
                   random_state=38)
) -> Fitness: 0.819015160808849

10: Pipeline(
	0: ExtraTreesClassifier(bootstrap=True, class_weight='balanced_subsample',
                     criterion='entropy', min_samples_leaf=3,
                     min_samples_split=6, n_estimators=99, random_state=38)
) -> Fitness: 0.8270926618822712

11: Pipeline(
	0: RandomForestClassifier(class_weight='balanced', criterion='entropy',
                       min_samples_leaf=10, min_samples_split=19,
                       n_estimators=58, random_state=38)
) -> Fitness: 0.8212103089410947

12: Pipeline(
	0: MinMaxScaler()
	1: FastICA(algorithm='deflation', n_components=55, random_state=38,
        whiten='arbitrary-variance')
	2: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', min_samples_leaf=3,
                     min_samples_split=6, n_estimators=99, random_state=38)
) -> Fitness: 0.8322343535954527

13: Pipeline(
	0: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    max_depth=4,
                                                    max_features=0.3258560672238251,
                                                    min_samples_leaf=16,
                                                    min_samples_split=12,
                                                    random_state=38),
                   learning_rate=0.09285916727857113, n_estimators=52,
                   random_state=38)
) -> Fitness: 0.8254145453801959

14: Pipeline(
	0: SelectPercentile(percentile=64.5924672763016)
	1: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                       max_depth=8, max_features=0.9404909891387785,
                       min_samples_leaf=6, random_state=38)
) -> Fitness: 0.8085081477846614

15: Pipeline(
	0: MinMaxScaler()
	1: MaxAbsScaler()
	2: VarianceThreshold()
	3: FastICA(algorithm='deflation', fun='exp', n_components=74, random_state=38,
        whiten='arbitrary-variance')
	4: ExtraTreesClassifier(class_weight='balanced', criterion='entropy',
                     max_features='log2', min_samples_leaf=7,
                     min_samples_split=18, n_estimators=68, random_state=38)
) -> Fitness: 0.8078318918808399

16: Pipeline(
	0: MaxAbsScaler()
	1: RobustScaler(with_scaling=False)
	2: SelectPercentile(percentile=80.87182579566738)
	3: ExtraTreesClassifier(bootstrap=True, class_weight='balanced_subsample',
                     criterion='entropy', min_samples_leaf=3,
                     min_samples_split=6, n_estimators=99, random_state=38)
) -> Fitness: 0.8204696477130998

17: Pipeline(
	0: MaxAbsScaler()
	1: RobustScaler(with_centering=False)
	2: RandomForestClassifier(class_weight='balanced', criterion='entropy',
                       max_features=None, min_samples_leaf=7,
                       min_samples_split=10, n_estimators=93, random_state=38)
) -> Fitness: 0.8314990594778058

18: Pipeline(
	0: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    max_depth=4,
                                                    max_features=0.3258560672238251,
                                                    min_samples_leaf=2,
                                                    min_samples_split=5,
                                                    random_state=38),
                   learning_rate=0.09285916727857113, n_estimators=52,
                   random_state=38)
) -> Fitness: 0.8219509701690896

19: Pipeline(
	0: MaxAbsScaler()
	1: VarianceThreshold()
	2: RandomForestClassifier(bootstrap=False, class_weight='balanced',
                       criterion='entropy', min_samples_leaf=16,
                       min_samples_split=10, n_estimators=93, random_state=38)
) -> Fitness: 0.823224764358298

Ensemble fitness: 0.8285578830072173
Weights: [1.0, 0.9913084613239577, 0.9871963354987333, 0.9871835913071262, 0.9845837762192777, 0.9921623221616334, 0.9939210206034133, 0.9845837762192777, 0.9741016786224378, 0.9723748406596756, 0.9819648448440187, 0.9749810278433277, 0.9880693126238196, 0.979972502889442, 0.9599004011082592, 0.9590975170370118, 0.9741016786224378, 0.9871963354987333, 0.9758603770642177, 0.9773726878015934]
Prediction: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0
 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0]
