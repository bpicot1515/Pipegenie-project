0: Pipeline(
	0: MaxAbsScaler()
	1: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', min_samples_leaf=7,
                     min_samples_split=12, n_estimators=73, random_state=35)
) -> Fitness: 0.8179634541703509

1: Pipeline(
	0: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', min_samples_leaf=7,
                     min_samples_split=12, n_estimators=73, random_state=35)
) -> Fitness: 0.8179634541703509

2: Pipeline(
	0: VarianceThreshold()
	1: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', min_samples_leaf=7,
                     min_samples_split=12, n_estimators=73, random_state=35)
) -> Fitness: 0.8179634541703509

3: Pipeline(
	0: MinMaxScaler()
	1: VarianceThreshold()
	2: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    criterion='entropy',
                                                    max_depth=5,
                                                    max_features=0.742853381455576,
                                                    min_samples_leaf=6,
                                                    min_samples_split=9,
                                                    random_state=35),
                   learning_rate=0.4898342056581443, n_estimators=27,
                   random_state=35)
) -> Fitness: 0.8114500442086647

4: Pipeline(
	0: MinMaxScaler()
	1: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     max_features='log2', min_samples_leaf=9,
                     min_samples_split=16, n_estimators=29, random_state=35)
) -> Fitness: 0.8048818997094859

5: Pipeline(
	0: MaxAbsScaler()
	1: RobustScaler(with_centering=False, with_scaling=False)
	2: MinMaxScaler()
	3: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    max_depth=28,
                                                    max_features=0.007323029646424173,
                                                    min_samples_leaf=9,
                                                    min_samples_split=3,
                                                    random_state=35),
                   learning_rate=0.024445985545675192, n_estimators=56,
                   random_state=35)
) -> Fitness: 0.8028819839164667

6: Pipeline(
	0: MinMaxScaler()
	1: MaxAbsScaler()
	2: Nystroem(coef0=0.37420395377160554, degree=5, gamma=1.6219974108520137,
         kernel='cosine', n_components=24, random_state=35)
	3: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', min_samples_leaf=7,
                     min_samples_split=12, n_estimators=73, random_state=35)
) -> Fitness: 0.8042524525283147

7: Pipeline(
	0: MaxAbsScaler()
	1: RobustScaler(with_centering=False, with_scaling=False)
	2: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', max_features='log2',
                     min_samples_leaf=16, min_samples_split=14, n_estimators=67,
                     random_state=35)
) -> Fitness: 0.7936086901604142

8: Pipeline(
	0: MaxAbsScaler()
	1: RobustScaler(with_centering=False, with_scaling=False)
	2: Nystroem(coef0=-0.7441737249633977, degree=3, gamma=0.3827893762276902,
         kernel='poly', n_components=50, random_state=35)
	3: LogisticRegression(C=13.567480715911582, class_weight='balanced', max_iter=1000,
                   random_state=35, solver='sag')
) -> Fitness: 0.7648793735000632

9: Pipeline(
	0: RobustScaler()
	1: VarianceThreshold()
	2: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       max_features=0.7755013237310036, min_samples_leaf=19,
                       min_samples_split=13, n_estimators=67, random_state=35)
) -> Fitness: 0.7882110226937814

10: Pipeline(
	0: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       max_features=0.7755013237310036, min_samples_leaf=19,
                       min_samples_split=13, n_estimators=67, random_state=35)
) -> Fitness: 0.7882110226937814

11: Pipeline(
	0: VarianceThreshold()
	1: LogisticRegression(C=9.5287620302258, class_weight='balanced', max_iter=1000,
                   penalty=None, random_state=35, solver='newton-cg')
) -> Fitness: 0.7629931371310682

12: Pipeline(
	0: VarianceThreshold()
	1: LogisticRegression(C=15.976712591979675, class_weight='balanced', max_iter=1000,
                   random_state=35)
) -> Fitness: 0.7606942865563555

13: Pipeline(
	0: VarianceThreshold()
	1: MaxAbsScaler()
	2: MinMaxScaler()
	3: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                       max_depth=24, max_features=0.589235908595741,
                       min_samples_leaf=20, min_samples_split=12,
                       random_state=35)
) -> Fitness: 0.7712496315944591

14: Pipeline(
	0: VarianceThreshold()
	1: LogisticRegression(C=1.5424064227159953, class_weight='balanced', max_iter=1000,
                   random_state=35, solver='liblinear')
) -> Fitness: 0.7582038651004168

15: Pipeline(
	0: RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',
                       max_features=0.9769545076232473, min_samples_leaf=7,
                       min_samples_split=16, n_estimators=79, random_state=35)
) -> Fitness: 0.7830112416319313

16: Pipeline(
	0: SelectPercentile(percentile=81.51275999213227)
	1: RobustScaler(with_scaling=False)
	2: VarianceThreshold()
	3: RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',
                       max_features=0.7755013237310036, min_samples_leaf=19,
                       min_samples_split=13, n_estimators=45, random_state=35)
) -> Fitness: 0.7758957517578207

17: Pipeline(
	0: MinMaxScaler()
	1: Nystroem(coef0=0.3910188187695536, degree=4, gamma=4.333362459750027,
         kernel='poly', n_components=78, random_state=35)
	2: RandomForestClassifier(class_weight='balanced', max_features=0.7251678004105224,
                       min_samples_leaf=20, min_samples_split=14,
                       n_estimators=35, random_state=35)
) -> Fitness: 0.7811207949138984

18: Pipeline(
	0: MinMaxScaler()
	1: MaxAbsScaler()
	2: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                       max_depth=27, max_features=0.8767342343987324,
                       min_samples_leaf=19, min_samples_split=9,
                       random_state=35)
) -> Fitness: 0.765226727295693

19: Pipeline(
	0: RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',
                       min_samples_leaf=15, min_samples_split=20,
                       n_estimators=49, random_state=35)
) -> Fitness: 0.778413540482506

Ensemble fitness: 0.8085470085470086
Weights: [1.0, 1.0, 1.0, 0.9920370403732859, 0.9840071651194571, 0.9815621710517848, 0.9832376354076319, 0.9702251196116832, 0.9351021364100794, 0.9636262093069342, 0.9636262093069342, 0.9327961209525696, 0.9299856646137293, 0.942890085935107, 0.9269410035799859, 0.9572692247309861, 0.9485701932060047, 0.9549580619175444, 0.9355267932744648, 0.9516483120533058]
Prediction: [0 0 0 ... 0 0 1]
