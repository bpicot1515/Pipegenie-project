0: Pipeline(
	0: RobustScaler()
	1: FastICA(algorithm='deflation', fun='cube', n_components=64, random_state=35,
        whiten='arbitrary-variance')
	2: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    max_depth=26,
                                                    max_features=0.6732768443433007,
                                                    min_samples_leaf=18,
                                                    min_samples_split=16,
                                                    random_state=35),
                   learning_rate=0.09053390550955631, n_estimators=21,
                   random_state=35)
) -> Fitness: 0.8016806722689076

1: Pipeline(
	0: MinMaxScaler()
	1: ExtraTreesClassifier(class_weight='balanced', max_features='log2',
                     min_samples_leaf=9, min_samples_split=16, n_estimators=29,
                     random_state=35)
) -> Fitness: 0.7934873949579833

2: Pipeline(
	0: MinMaxScaler()
	1: ExtraTreesClassifier(class_weight='balanced_subsample', max_features='log2',
                     min_samples_leaf=9, min_samples_split=16, n_estimators=29,
                     random_state=35)
) -> Fitness: 0.7934873949579833

3: Pipeline(
	0: RobustScaler(with_centering=False)
	1: FastICA(algorithm='deflation', fun='cube', n_components=64, random_state=35,
        whiten='arbitrary-variance')
	2: ExtraTreesClassifier(class_weight='balanced_subsample', criterion='entropy',
                     min_samples_leaf=5, min_samples_split=14, n_estimators=82,
                     random_state=35)
) -> Fitness: 0.7885504201680672

4: Pipeline(
	0: SelectPercentile(percentile=77.57180816060706)
	1: VarianceThreshold()
	2: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    max_depth=28,
                                                    max_features=0.007323029646424173,
                                                    min_samples_leaf=9,
                                                    min_samples_split=17,
                                                    random_state=35),
                   learning_rate=0.024445985545675192, n_estimators=56,
                   random_state=35)
) -> Fitness: 0.7886904761904762

5: Pipeline(
	0: MinMaxScaler()
	1: MaxAbsScaler()
	2: ExtraTreesClassifier(class_weight='balanced_subsample', max_features='log2',
                     min_samples_leaf=9, min_samples_split=16, n_estimators=29,
                     random_state=35)
) -> Fitness: 0.7934873949579833

6: Pipeline(
	0: Nystroem(coef0=0.9243399370409886, degree=3, gamma=0.03874513980783196,
         kernel='poly', n_components=70, random_state=35)
	1: ExtraTreesClassifier(class_weight='balanced', min_samples_leaf=16,
                     min_samples_split=14, n_estimators=68, random_state=35)
) -> Fitness: 0.7663165266106443

7: Pipeline(
	0: MinMaxScaler()
	1: MaxAbsScaler()
	2: ExtraTreesClassifier(class_weight='balanced', max_features='log2',
                     min_samples_leaf=9, min_samples_split=16, n_estimators=29,
                     random_state=35)
) -> Fitness: 0.7934873949579833

8: Pipeline(
	0: MinMaxScaler()
	1: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     max_features='log2', min_samples_leaf=6,
                     min_samples_split=10, n_estimators=99, random_state=35)
) -> Fitness: 0.7813375350140055

9: Pipeline(
	0: Nystroem(coef0=0.9243399370409886, degree=3, gamma=0.03874513980783196,
         kernel='poly', n_components=70, random_state=35)
	1: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', max_features='log2',
                     min_samples_leaf=14, min_samples_split=9, n_estimators=68,
                     random_state=35)
) -> Fitness: 0.7658263305322128

10: Pipeline(
	0: MaxAbsScaler()
	1: RobustScaler(with_centering=False, with_scaling=False)
	2: MinMaxScaler()
	3: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    max_depth=28,
                                                    max_features=0.007323029646424173,
                                                    min_samples_leaf=9,
                                                    min_samples_split=3,
                                                    random_state=35),
                   learning_rate=0.024445985545675192, n_estimators=56,
                   random_state=35)
) -> Fitness: 0.7595588235294117

11: Pipeline(
	0: RobustScaler()
	1: MinMaxScaler()
	2: ExtraTreesClassifier(class_weight='balanced_subsample', criterion='entropy',
                     min_samples_leaf=5, min_samples_split=4, n_estimators=69,
                     random_state=35)
) -> Fitness: 0.775875350140056

12: Pipeline(
	0: VarianceThreshold()
	1: FastICA(algorithm='deflation', fun='cube', n_components=64, random_state=35,
        whiten='arbitrary-variance')
	2: ExtraTreesClassifier(class_weight='balanced_subsample', criterion='entropy',
                     min_samples_leaf=5, min_samples_split=14, n_estimators=82,
                     random_state=35)
) -> Fitness: 0.777906162464986

13: Pipeline(
	0: MaxAbsScaler()
	1: RobustScaler(with_centering=False, with_scaling=False)
	2: ExtraTreesClassifier(class_weight='balanced', max_features='log2',
                     min_samples_leaf=9, min_samples_split=6, n_estimators=83,
                     random_state=35)
) -> Fitness: 0.781232492997199

14: Pipeline(
	0: RobustScaler(with_centering=False)
	1: MinMaxScaler()
	2: ExtraTreesClassifier(class_weight='balanced', criterion='entropy',
                     min_samples_leaf=8, min_samples_split=4, n_estimators=83,
                     random_state=35)
) -> Fitness: 0.78343837535014

15: Pipeline(
	0: MinMaxScaler()
	1: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     criterion='entropy', max_features='log2',
                     min_samples_leaf=9, min_samples_split=16, n_estimators=29,
                     random_state=35)
) -> Fitness: 0.7682422969187674

16: Pipeline(
	0: AdaBoostClassifier(algorithm='SAMME',
                   estimator=DecisionTreeClassifier(class_weight='balanced',
                                                    criterion='entropy',
                                                    max_depth=7,
                                                    max_features=0.11646957081906506,
                                                    min_samples_leaf=4,
                                                    random_state=35),
                   learning_rate=0.5715430355650364, n_estimators=17,
                   random_state=35)
) -> Fitness: 0.770658263305322

17: Pipeline(
	0: MinMaxScaler()
	1: ExtraTreesClassifier(class_weight='balanced', criterion='entropy',
                     max_features='log2', min_samples_leaf=9,
                     min_samples_split=16, n_estimators=29, random_state=35)
) -> Fitness: 0.7768207282913165

18: Pipeline(
	0: MinMaxScaler()
	1: ExtraTreesClassifier(class_weight='balanced_subsample', criterion='entropy',
                     max_features='log2', min_samples_leaf=9,
                     min_samples_split=16, n_estimators=29, random_state=35)
) -> Fitness: 0.7768207282913165

19: Pipeline(
	0: Nystroem(coef0=0.9243399370409886, degree=3, gamma=0.03874513980783196,
         kernel='poly', n_components=70, random_state=35)
	1: ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                     max_features='log2', min_samples_leaf=14,
                     min_samples_split=9, n_estimators=68, random_state=35)
) -> Fitness: 0.7621498599439775

Ensemble fitness: 0.8214285714285715
Weights: [1.0, 0.9897798742138365, 0.9897798742138365, 0.9836215932914045, 0.9837962962962962, 0.9897798742138365, 0.9558874912648497, 0.9897798742138365, 0.9746243885394827, 0.9552760307477287, 0.9474580712788259, 0.9678109713487072, 0.9703441649196366, 0.9744933612858142, 0.9772449336128581, 0.9582896575821103, 0.9613032844164918, 0.968990216631726, 0.968990216631726, 0.950690076869322]
Prediction: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0
 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0
 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1
 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0
 0 0 0 1 1 0 0 0 0]
